{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXy8oVoyVBcTYZUqey2C3i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Name**: **Rhythm** **sethiya**\n","\n","**Roll** **No**: **57**\n","\n","**Prn**: **1032212447**"],"metadata":{"id":"GsLjfLWCZISn"}},{"cell_type":"markdown","source":["  **DEC** **ASSIGNMENT**-**03**\n","\n"," ** part-01 Data integration**\n"],"metadata":{"id":"ceMfnJe_ZaKD"}},{"cell_type":"markdown","source":["**Data redundancy has a number of advantages and disadvantages.**\n","\n","Advantages:\n","\n","Improved data availability and reliability: If one copy of the data is lost or corrupted, the other copies can still be used.\n","Improved data integrity: Multiple copies of the data can be compared to detect and correct errors.\n","Increased fault tolerance: The system can continue to function even if one copy of the data is lost or corrupted.\n","\n","\n","Disadvantages:\n","\n","Increased storage requirements: Multiple copies of the data must be maintained.\n","Increased complexity of the system: Managing multiple copies of the data can be difficult and time-consuming.\n","Increased risk of data inconsistencies: If updates are not properly propagated to all copies of the data, the different copies may become out of sync."],"metadata":{"id":"mgtb9k1_YusM"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"2vPvHAhYVWCt","executionInfo":{"status":"ok","timestamp":1695058342020,"user_tz":-330,"elapsed":197584,"user":{"displayName":"rhythm sethiya","userId":"00661148982242432154"}},"outputId":"e27b35a4-fb0f-4247-ecd5-c21044c69de9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-18eadaee-168e-4eea-99a1-5209ec9298fb\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-18eadaee-168e-4eea-99a1-5209ec9298fb\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Preprocessed World University Rankings 2023 Dataset.csv to Preprocessed World University Rankings 2023 Dataset.csv\n"]}],"source":["from google.colab import files\n","\n","# Use files.upload() to upload a file\n","uploaded = files.upload()\n"]},{"cell_type":"markdown","source":["**Theory:**\n","\n","**1. Pearson Correlation: NumPy and SciPy Implementation:**\n","\n","The Pearson correlation coefficient, often denoted as \"r,\" measures the linear relationship between two continuous variables. It quantifies how well the data fits a straight line. The formula for Pearson correlation is:\n","\n","- **NumPy Implementation**: You can calculate Pearson correlation in NumPy using the `numpy.corrcoef()` function. It takes two arrays as input and returns the correlation coefficient between them.\n","\n","- **SciPy Implementation**: SciPy offers more advanced statistical tools. You can use `scipy.stats.pearsonr()` to compute the Pearson correlation coefficient along with the p-value to test for correlation significance.\n","\n","**2. Pearson Correlation: pandas Implementation:**\n","\n","- In pandas, you can calculate the Pearson correlation coefficient between columns of a DataFrame using the `corr()` method. This method computes the correlation matrix for all pairs of numeric columns.\n","\n","```python\n","correlation_matrix = df.corr()\n","```\n","\n","**3. Visualization of Correlation:**\n","\n","Visualizing correlations helps you gain insights into relationships between variables. Heatmaps are commonly used for this purpose.\n","\n","**Heatmaps of Correlation Matrices:**\n","\n","- A heatmap is a graphical representation of data where values are represented as colors. When visualizing a correlation matrix as a heatmap, you can quickly identify patterns of correlation (positive or negative) between variables. Seaborn and Matplotlib are popular libraries for creating heatmaps in Python.\n","\n","**4. Feature Normalization and Their Techniques:**\n","\n","Feature normalization is the process of scaling or transforming feature values to a similar range. It's important for many machine learning algorithms that are sensitive to the scale of input features. Common techniques include:\n","\n","- **Min-Max Scaling**: Rescales features to a specific range (e.g., [0, 1]) using the formula:\n","  ```\n","  X_scaled = (X - X_min) / (X_max - X_min)\n","  ```\n","\n","- **Z-Score Standardization**: Standardizes features to have a mean of 0 and a standard deviation of 1. It is achieved using:\n","  ```\n","  X_standardized = (X - mean(X)) / std(X)\n","  ```\n","\n","- **Robust Scaling**: It's similar to min-max scaling but is less affected by outliers. It scales features to a specified range using the interquartile range (IQR).\n","\n","- **Log Transformation**: Used when data is not normally distributed. It can make data more symmetric and reduce the impact of outliers."],"metadata":{"id":"FlRhh0YghUZc"}},{"cell_type":"markdown","source":["**Data redundancy and tuple duplication**\n","\n","Data redundancy occurs when the same data is stored in multiple locations. This can happen for a variety of reasons, such as:\n","      Data duplication during data entry or transfer\n","      Data synchronization errors\n","      Different systems storing the same data for different purposes"],"metadata":{"id":"ETy-FPmTXSdp"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the CSV file into a Pandas DataFrame\n","df = pd.read_csv(\"Preprocessed World University Rankings 2023 Dataset.csv\")\n"],"metadata":{"id":"q6HKClwgVn5O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using the drop_duplicates() method in Pandas:\n","> The drop_duplicates() method in Pandas can be used to remove duplicate rows from a DataFrame. The drop_duplicates() method takes a number of parameters, including the subset parameter, which can be used to specify the columns to be used to identify duplicate rows.\n","\n"],"metadata":{"id":"TlfQ5_mMYKRt"}},{"cell_type":"code","source":["# Remove duplicate rows\n","df.drop_duplicates(inplace=True)\n","# Remove tuple duplication\n","df.drop_duplicates(subset=df.columns, inplace=True)\n","# Save the results to a new CSV file\n","df.to_csv(\"dataset_no_duplicates.csv\", index=False)"],"metadata":{"id":"ntzZDYDgWsat"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1  = pd.read_csv(\"dataset_no_duplicates.csv\")\n","print(df1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWuWdTunW_2r","executionInfo":{"status":"ok","timestamp":1695058554713,"user_tz":-330,"elapsed":584,"user":{"displayName":"rhythm sethiya","userId":"00661148982242432154"}},"outputId":"b776cc4d-bcf4-4622-f135-fb7e6fbbd3d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      No of student  No of student per staff  International Student  \\\n","0      20965.000000                10.600000               0.420000   \n","1      21887.000000                 9.600000               0.250000   \n","2      20185.000000                11.300000               0.390000   \n","3      16164.000000                 7.100000               0.240000   \n","4      11415.000000                 8.200000               0.330000   \n","...             ...                      ...                    ...   \n","2307   19617.416478                19.000408               0.101265   \n","2308   19617.416478                19.000408               0.101265   \n","2309   19617.416478                19.000408               0.101265   \n","2310   19617.416478                19.000408               0.101265   \n","2311   19617.416478                19.000408               0.101265   \n","\n","      Teaching Score  Research Score  Citations Score  Industry Income Score  \\\n","0               92.3            99.7             99.0                   74.9   \n","1               94.8            99.0             99.3                   49.5   \n","2               90.9            99.5             97.0                   54.2   \n","3               94.2            96.7             99.8                   65.0   \n","4               90.7            93.6             99.8                   90.9   \n","...              ...             ...              ...                    ...   \n","2307            24.1            15.5             61.5                   37.9   \n","2308            35.1            29.4             34.5                   44.2   \n","2309            18.2            14.3             68.8                   37.3   \n","2310            26.4            26.7             52.8                   52.1   \n","2311            17.8            14.8             68.2                   38.2   \n","\n","      International Outlook Score  Female Ratio  Male Ratio  ...  \\\n","0                            96.2     48.000000   52.000000  ...   \n","1                            80.5     50.000000   50.000000  ...   \n","2                            95.8     47.000000   53.000000  ...   \n","3                            79.8     46.000000   54.000000  ...   \n","4                            89.3     40.000000   60.000000  ...   \n","...                           ...           ...         ...  ...   \n","2307                         76.8     50.843045   49.156955  ...   \n","2308                         88.7     50.843045   49.156955  ...   \n","2309                         72.0     50.843045   49.156955  ...   \n","2310                         47.6     50.843045   49.156955  ...   \n","2311                         72.4     50.843045   49.156955  ...   \n","\n","      Location_United Kingdom  Location_United States  \\\n","0                           1                       0   \n","1                           0                       1   \n","2                           1                       0   \n","3                           0                       1   \n","4                           0                       1   \n","...                       ...                     ...   \n","2307                        0                       0   \n","2308                        0                       0   \n","2309                        0                       0   \n","2310                        0                       0   \n","2311                        0                       0   \n","\n","      Location_Unknown Location  Location_Uruguay  Location_Uzbekistan  \\\n","0                             0                 0                    0   \n","1                             0                 0                    0   \n","2                             0                 0                    0   \n","3                             0                 0                    0   \n","4                             0                 0                    0   \n","...                         ...               ...                  ...   \n","2307                          1                 0                    0   \n","2308                          1                 0                    0   \n","2309                          1                 0                    0   \n","2310                          1                 0                    0   \n","2311                          1                 0                    0   \n","\n","      Location_Venezuela  Location_Vietnam  Location_Zambia  \\\n","0                      0                 0                0   \n","1                      0                 0                0   \n","2                      0                 0                0   \n","3                      0                 0                0   \n","4                      0                 0                0   \n","...                  ...               ...              ...   \n","2307                   0                 0                0   \n","2308                   0                 0                0   \n","2309                   0                 0                0   \n","2310                   0                 0                0   \n","2311                   0                 0                0   \n","\n","      Location_Zimbabwe  University Rank  \n","0                     0                1  \n","1                     0                2  \n","2                     0                3  \n","3                     0                3  \n","4                     0                5  \n","...                 ...              ...  \n","2307                  0                -  \n","2308                  0                -  \n","2309                  0                -  \n","2310                  0                -  \n","2311                  0                -  \n","\n","[2312 rows x 2362 columns]\n"]}]},{"cell_type":"markdown","source":["Removing duplicate rows and tuple duplication is an important task for ensuring the accuracy, efficiency, and consistency of data. By using the methods described above, organizations can improve the quality of their data systems."],"metadata":{"id":"AKnWVfdqYky9"}}]}